{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import ensemble\n",
    "import pandas as pd\n",
    "data_breast_cancer_X, data_breast_cancer_y = datasets.load_breast_cancer(return_X_y= True, as_frame=True)\n",
    "data_breast_cancer_X = data_breast_cancer_X[['mean texture','mean symmetry']]\n",
    "data_breast_cancer_X\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_breast_cancer_X, data_breast_cancer_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tworzenie estymatorów \n",
    "# 1.drzewa \n",
    "# 2.regresja logistyczna\n",
    "# 3.knn\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "log_clf = LogisticRegression()\n",
    "knn_clf = KNeighborsClassifier()\n",
    "\n",
    "voting_clf_hard = VotingClassifier(\n",
    "    estimators=[('tree', tree_clf), ('log', log_clf), ('knn', knn_clf)],\n",
    "    voting='hard'\n",
    ")\n",
    "voting_clf_soft = VotingClassifier(\n",
    "    estimators=[('tree', tree_clf), ('log', log_clf), ('knn', knn_clf)],\n",
    "    voting='soft'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('tree', DecisionTreeClassifier()),\n",
       "                             ('log', LogisticRegression()),\n",
       "                             ('knn', KNeighborsClassifier())],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf_hard.fit(X_train, y_train)\n",
    "voting_clf_soft.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8351648351648352, 0.6929824561403509) (0.9648351648351648, 0.6666666666666666)\n"
     ]
    }
   ],
   "source": [
    "#liczenie dokładności dla głosowanie hard i soft\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_test_predict_hard = voting_clf_hard.predict(X_test)\n",
    "y_test_predict_soft = voting_clf_soft.predict(X_test)\n",
    "\n",
    "y_train_predict_hard = voting_clf_hard.predict(X_train)\n",
    "y_train_predict_soft = voting_clf_soft.predict(X_train)\n",
    "\n",
    "y_test_predict_hard_score = accuracy_score(y_test, y_test_predict_hard)\n",
    "y_test_predict_soft_score = accuracy_score(y_test, y_test_predict_soft)\n",
    "\n",
    "y_train_predict_hard_score = accuracy_score(y_train, y_train_predict_hard)\n",
    "y_train_predict_soft_score = accuracy_score(y_train, y_train_predict_soft)\n",
    "\n",
    "voting_clf_hard_scores = (y_train_predict_hard_score, y_test_predict_hard_score)\n",
    "voting_clf_soft_scores = (y_train_predict_soft_score, y_test_predict_soft_score)\n",
    "\n",
    "print(voting_clf_hard_scores, voting_clf_soft_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores = []\n",
    "clfs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.6140350877192983 DecisionTreeClassifier\n",
      "0.7230769230769231 0.7017543859649122 LogisticRegression\n",
      "0.7714285714285715 0.6403508771929824 KNeighborsClassifier\n"
     ]
    }
   ],
   "source": [
    "# dokładności dla kazdego z samych estymatorów\n",
    "for estimator in voting_clf_hard.estimators_:\n",
    "    accuracy_score_train = accuracy_score(y_train, estimator.predict(X_train))\n",
    "    accuracy_score_test = accuracy_score(y_test, estimator.predict(X_test))\n",
    "    print(accuracy_score_train, accuracy_score_test, estimator.__class__.__name__)\n",
    "    accuracy_scores.append((accuracy_score_train, accuracy_score_test))\n",
    "    clfs.append(estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1.0, 0.6140350877192983), (0.7230769230769231, 0.7017543859649122), (0.7714285714285715, 0.6403508771929824), (0.8351648351648352, 0.6929824561403509), (0.9648351648351648, 0.6666666666666666)]\n"
     ]
    }
   ],
   "source": [
    "accuracy_scores.append(voting_clf_hard_scores)\n",
    "accuracy_scores.append(voting_clf_soft_scores)\n",
    "print(accuracy_scores)\n",
    "\n",
    "clfs.append(voting_clf_hard)\n",
    "clfs.append(voting_clf_soft)\n",
    "\n",
    "import pickle\n",
    "with open('acc_vote.pkl', 'wb') as f:\n",
    "    pickle.dump(accuracy_scores, f)\n",
    "\n",
    "with open('vote.pkl', 'wb') as f:\n",
    "    pickle.dump(clfs, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores_trees = []\n",
    "clfs_trees = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9956043956043956 0.6754385964912281 BaggingClassifier 0\n",
      "0.9296703296703297 0.6842105263157895 BaggingClassifier 1\n",
      "1.0 0.6228070175438597 BaggingClassifier 2\n",
      "0.9736263736263736 0.6491228070175439 BaggingClassifier 3\n",
      "0.9956043956043956 0.6754385964912281 RandomForestClassifier 4\n",
      "0.8 0.7368421052631579 AdaBoostClassifier 5\n",
      "0.8373626373626374 0.7105263157894737 GradientBoostingClassifier 6\n"
     ]
    }
   ],
   "source": [
    "# 6 bagginc clf, bagging 50 prc, pasting, pasting 50 prc, random forest, adaboost, gradient boosing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "bgg_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=30, random_state=42)\n",
    "bgg_clf_50 = BaggingClassifier(DecisionTreeClassifier(), n_estimators=30, max_samples=.5, random_state=42)\n",
    "pst_clf = BaggingClassifier(DecisionTreeClassifier(), bootstrap=False, n_estimators=30, random_state=42)\n",
    "pst_clf_50 = BaggingClassifier(DecisionTreeClassifier(), bootstrap=False, n_estimators=30, max_samples=.5, random_state=42)\n",
    "rnd_clf = RandomForestClassifier(n_estimators=30, random_state=42)\n",
    "ada_clf = AdaBoostClassifier(n_estimators=30, random_state=42)\n",
    "grd_clf = GradientBoostingClassifier(n_estimators=30, random_state=42)\n",
    "\n",
    "for i, estimator in enumerate([bgg_clf, bgg_clf_50, pst_clf, pst_clf_50, rnd_clf, ada_clf, grd_clf]):\n",
    "    estimator.fit(X_train, y_train)\n",
    "    acc_train = accuracy_score(y_train, estimator.predict(X_train))\n",
    "    acc_test = accuracy_score(y_test, estimator.predict(X_test))\n",
    "    print(acc_train, acc_test, estimator.__class__.__name__,i)\n",
    "    accuracy_scores_trees.append((acc_train, acc_test))\n",
    "    clfs_trees.append(estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('acc_bag.pkl', 'wb') as f:\n",
    "    pickle.dump(accuracy_scores_trees, f)\n",
    "\n",
    "with open('bag.pkl', 'wb') as f:\n",
    "    pickle.dump(clfs_trees, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error', 'fractal dimension error',\n",
       "       'worst radius', 'worst texture', 'worst perimeter', 'worst area',\n",
       "       'worst smoothness', 'worst compactness', 'worst concavity',\n",
       "       'worst concave points', 'worst symmetry', 'worst fractal dimension'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#7. sampling \n",
    "data_breast_cancer_X, data_breast_cancer_y = datasets.load_breast_cancer(return_X_y= True, as_frame=True)\n",
    "#data_breast_cancer_X = data_breast_cancer_X[['mean texture','mean symmetry']]\n",
    "data_breast_cancer_X\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_breast_cancer_X, data_breast_cancer_y, test_size=0.2, random_state=42)\n",
    "data_breast_cancer_X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean radius 0.04706475687207926\n",
      "mean texture 0.016359326862804082\n",
      "mean perimeter 0.041768943622206234\n",
      "mean area 0.040207440805062056\n",
      "mean smoothness 0.007518062679254841\n",
      "mean compactness 0.012101887153474402\n",
      "mean concavity 0.051091160395859585\n",
      "mean concave points 0.11533220743928123\n",
      "mean symmetry 0.003570340625580548\n",
      "mean fractal dimension 0.004723438579581869\n",
      "radius error 0.016963074265710348\n",
      "texture error 0.004404533130902704\n",
      "perimeter error 0.010395285249577283\n",
      "area error 0.029796888704994265\n",
      "smoothness error 0.0034023295569631977\n",
      "compactness error 0.005323849038562246\n",
      "concavity error 0.007545928120234165\n",
      "concave points error 0.0045157165250521575\n",
      "symmetry error 0.004979756978372231\n",
      "fractal dimension error 0.0061489633752481775\n",
      "worst radius 0.08250625427779008\n",
      "worst texture 0.02100639840135993\n",
      "worst perimeter 0.11441049172818418\n",
      "worst area 0.12244813320331961\n",
      "worst smoothness 0.01310910823606547\n",
      "worst compactness 0.015939294523398435\n",
      "worst concavity 0.03843478553502979\n",
      "worst concave points 0.13971333981326875\n",
      "worst symmetry 0.013318967818411364\n",
      "worst fractal dimension 0.0058993364823716\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500,random_state=42)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "df = pd.DataFrame()\n",
    "for name, score in zip(X_test.columns, rnd_clf.feature_importances_):\n",
    "    print(name, score)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
